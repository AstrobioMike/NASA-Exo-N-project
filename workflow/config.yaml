#############################
###### VARIABLES TO SET #####
#############################

##### These first 6 need to match what is on our system #####
## path to single column file holding unique portion of sample names, e.g.:
        # Sample-1
        # Sample-2

sample_IDs_file:
    "test-unique-sample-IDs.txt"

## path to single column file holding all groups of samples (for co-assembly if appropriate), e.g.:
        # Group_1
        # Group_2

group_IDs_file:
    "groups.txt"

## path to 2-column, tab-delimited file specifying what group each sample belongs to, e.g.:
        # Sample-1  Group_1
        # Sample-2  Group_1
        # Sample-3  Group_2
        # Sample-4  Group_2

groups_map_file:
    "test-sample-groups-map.tsv"


## raw read suffixes (region following the unique part of the sample names)
  # e.g. for Sample-1-R1.fq.gz and Sample-1-R2.fq.gz

raw_R1_suffix:
    "-R1.fq.gz"
raw_R2_suffix:
    "-R2.fq.gz"

## raw reads directory (can be relative to workflow directory)
raw_reads_dir:
    "../raw-reads/"


##### The rest only need to be altered if we want to change them #####

## number of threads to use PER snakemake job (which is set with the -j parameter passed to snakemake call)
    # passed to megahit, bowtie2, samtools, metabat2, checkm-pplacer (many may be running concurrently)
num_threads:
    10

## number of CPUs to use PER snakemake job
    # passed to KOFamScan, CAT, checkm (many may be running concurrently)
num_cpus:
    10

## number of CPUs to use for gtdb-tk (only 1 will run at a time, but the pplacer step can be memory intensive with many cpus)
gtdb_tk_num_cpus:
    2

## maximum memory allowed passed to megahit assembler
    # can be set either by proportion of available on system, e.g. 0.5
    # or by absolute value in bytes, e.g. 100e9 would be 100 GB
max_mem:
    0.5

## quality trimmed/filtered read suffixes
trimmed_R1_suffix:
    "-R1-trimmed.fq.gz"
trimmed_R2_suffix:
    "-R2-trimmed.fq.gz"

## output directories (all relative to processing directory, will be created)
fastqc_out_dir:
    "../fastqc-outputs/"
filtered_reads_dir:
    "../filtered-reads/"
assemblies_dir:
    "../assemblies/"
genes_dir:
    "../predicted-genes/"
annotations_and_tax_dir:
    "../annotations-and-taxonomy/"
mapping_dir:
    "../read-mapping/"
combined_output_dir:
    "../combined-outputs/"
bins_dir:
    "../bins/"
MAGs_dir:
    "../MAGs/"



#############################
#### REFERENCE DATABASES ####
#############################
### Note on reference databases ###
# The workflow will check the locations pointed to below and install the databases
# if they are not already there. It looks for the below filenames in the directory
# for each database, which it creates when it sets them up initially. If we want to
# point to DBs that already exist on our setup, rather than setting up new ones, we
# need to add these files to their respective directories. They should be empty, the
# workflow just checks the file is there, to know it doesn't need to setup the DB.
#
# All together, after installed and unpacked, these will take up about 260 GB. But will 
# require up to 500 GB during installation and initial un-packing. 

## root directory of databases (or where they will be downloaded if they don't exist yet)
    # the root should be the full path or relative path, the ~/ home shortcut is not expanded
    # by snakemake's evaluation of files, so don't use that
REF_DB_ROOT_DIR:
    "/home/mdlee4/ref-dbs/"

## specific database locations
KOFAMSCAN_DIR:
    "kofamscan_db"
    # trigger file name: 
CAT_DIR:
    "CAT_prepare_20200618"
GTDB_DATA_PATH:
    "GTDB-tk-ref-db"
CHECKM_DIR:
    "checkm-db"
